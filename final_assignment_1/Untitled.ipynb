{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Version 11\n",
    "Second submission: I abandoned my text preprocessor and applied an alpha value of 100000. I wanted to find out if the text preprocessor didn't make much difference.\n",
    "\n",
    "# all imports and magic commands\n",
    "import re\n",
    "# import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# text preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from part_of_speech import get_part_of_speech\n",
    "\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "IMPORTANT!!! Make sure you are using BinaryClassificationPerformance v1.02\n",
    "help(BinaryClassificationPerformance)\n",
    "Help on class BinaryClassificationPerformance in module my_measures:\n",
    "\n",
    "class BinaryClassificationPerformance(builtins.object)\n",
    " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
    " |  \n",
    " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
    " |  \n",
    " |  Methods defined here:\n",
    " |  \n",
    " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
    " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
    " |  \n",
    " |  compute_measures(self)\n",
    " |      Compute performance measures defined by Flach p. 57\n",
    " |  \n",
    " |  img_indices(self)\n",
    " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
    " |  \n",
    " |  ----------------------------------------------------------------------\n",
    " |  Data descriptors defined here:\n",
    " |  \n",
    " |  __dict__\n",
    " |      dictionary for instance variables (if defined)\n",
    " |  \n",
    " |  __weakref__\n",
    " |      list of weak references to the object (if defined)\n",
    "\n",
    "Function for feature building and extraction on natural language data\n",
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    movie_data = pd.read_csv(fn, sep='\\t')\n",
    "    reviews = movie_data.review\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     porter_stemmer=PorterStemmer()\n",
    " #https://kavita-ganesan.com/how-to-use-countvectorizer/#.YjpnbprMIqw   \n",
    "#     def my_preprocessor(text):\n",
    "#         text=text.lower() \n",
    "#         text=re.sub(\"<.*?>\",\"\",text)#remove html tag\n",
    "#         text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "#         text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n",
    "    \n",
    "    # stem words\n",
    "    # words=re.split(\"\\\\s+\",text)\n",
    "    # stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "\n",
    "    # part_of_speech\n",
    "    # lemmatization\n",
    "#         tokenized_string = word_tokenize(text)\n",
    "#         stemmed_words = [lemmatizer.lemmatize(token, get_part_of_speech(token)) for token in tokenized_string]\n",
    "#         return ' '.join(stemmed_words)\n",
    "    \n",
    "#     print(my_preprocessor(\"<br>Testing if my_preprocessor worked?</br>\"))\n",
    "    print(movie_data.head(10))\n",
    "    print(\"movie_data is:\", type(movie_data))\n",
    "    print(\"movie_data has\", movie_data.shape[0], \"rows and\", movie_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in movie_data:\")\n",
    "    print(movie_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in movie_data:\")\n",
    "    print(movie_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'good' movie reviews in the dataset: \")\n",
    "        print(movie_data['sentiment'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        hv = CountVectorizer(ngram_range=(1,2))\n",
    "        X_hv = hv.fit_transform(reviews)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(reviews)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    movie_data['word_count'] = reviews.str.split(' ').str.len()\n",
    "    movie_data['punc_count'] = reviews.str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = movie_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = movie_data['sentiment']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(movie_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, movie_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)\n",
    "Create training and test sets from function\n",
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='../data/moviereviews_train.tsv', my_random_seed=73)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))\n",
    "        id  sentiment                                             review\n",
    "0   5814_8          1  With all this stuff going down at the moment w...\n",
    "1   2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
    "2   7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
    "3   3630_4          0  It must be assumed that those who praised this...\n",
    "4   9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
    "5   8196_8          1  I dont know why people think this is such a ba...\n",
    "6   7166_2          0  This movie could have been very good, but come...\n",
    "7  10633_1          0  I watched this video at a friend's house. I'm ...\n",
    "8    319_1          0  A friend of mine bought this film for Â£1, and ...\n",
    "9  8713_10          1  <br /><br />This movie is full of references. ...\n",
    "movie_data is: <class 'pandas.core.frame.DataFrame'>\n",
    "movie_data has 25000 rows and 3 columns \n",
    "\n",
    "the data types for each of the columns in movie_data:\n",
    "id           object\n",
    "sentiment     int64\n",
    "review       object\n",
    "dtype: object \n",
    "\n",
    "the first 10 rows in movie_data:\n",
    "       id  sentiment                                             review\n",
    "0  5814_8          1  With all this stuff going down at the moment w...\n",
    "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
    "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
    "3  3630_4          0  It must be assumed that those who praised this...\n",
    "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
    "The rate of 'good' movie reviews in the dataset: \n",
    "0.5\n",
    "Shape of HashingVectorizer X:\n",
    "(25000, 1513832)\n",
    "Look at a few rows of the new quantitative features: \n",
    "   word_count  punc_count\n",
    "0         433          20\n",
    "1         158          16\n",
    "2         378          20\n",
    "3         379           8\n",
    "4         367           9\n",
    "5          89           5\n",
    "6         112           9\n",
    "7         132           9\n",
    "8         163           7\n",
    "9          43           5\n",
    "Size of combined bag of words and new quantitative variables matrix:\n",
    "(25000, 1513834)\n",
    "(25000, 1513834)\n",
    "Shape of X_train and X_test:\n",
    "(20000, 1513834)\n",
    "(5000, 1513834)\n",
    "Shape of y_train and y_test:\n",
    "(20000,)\n",
    "(5000,)\n",
    "Shape of X_raw_train and X_raw_test:\n",
    "(20000, 5)\n",
    "(5000, 5)\n",
    "SUCCESS!\n",
    "Number of fits stored in `fitted_transformations` list: \n",
    "3\n",
    "Fit (and tune) Various Models\n",
    "MODEL: ordinary least squares\n",
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)\n",
    "print(\"performance_measures is:\", type(ols_performance_train.performance_measures))\n",
    "{'Pos': 10000, 'Neg': 10000, 'TP': 5153, 'TN': 5303, 'FP': 4697, 'FN': 4847, 'Accuracy': 0.5228, 'Precision': 0.5231472081218274, 'Recall': 0.5153, 'desc': 'ols_train'}\n",
    "performance_measures is: <class 'dict'>\n",
    "MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)\n",
    "{'Pos': 10000, 'Neg': 10000, 'TP': 10000, 'TN': 10000, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'svm_train'}\n",
    "MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)\n",
    "{'Pos': 10000, 'Neg': 10000, 'TP': 10000, 'TN': 10000, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'lgs_train'}\n",
    "MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(nbs_performance_train.performance_measures)\n",
    "{'Pos': 10000, 'Neg': 10000, 'TP': 10000, 'TN': 10000, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'nbs_train'}\n",
    "MODEL: Perceptron\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(prc_performance_train.performance_measures)\n",
    "{'Pos': 10000, 'Neg': 10000, 'TP': 10000, 'TN': 10000, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'prc_train'}\n",
    "MODEL: Ridge Regression Classifier\n",
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier(alpha=100000)\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg_train')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(rdg_performance_train.performance_measures)\n",
    "{'Pos': 10000, 'Neg': 10000, 'TP': 10000, 'TN': 10000, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'rdg_train'}\n",
    "MODEL: Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(rdf_performance_train.performance_measures)\n",
    "{'Pos': 10000, 'Neg': 10000, 'TP': 8334, 'TN': 6556, 'FP': 3444, 'FN': 1666, 'Accuracy': 0.7445, 'Precision': 0.7075904228222109, 'Recall': 0.8334, 'desc': 'rdf_train'}\n",
    "ROC plot to compare performance of various models and fits\n",
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train, rdg_performance_train, rdf_performance_train]\n",
    "\n",
    "fig = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0.4, 1])\n",
    "plt.yticks(np.arange(0.4, 1, 0.05))\n",
    "plt.title('ROC plot: test set')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.show()\n",
    "\n",
    "Create Pivot Table\n",
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train, rdg_performance_train, rdf_performance_train]\n",
    "\n",
    "TP_rate =[]\n",
    "FP_rate =[]\n",
    "rows = ['ordinary least sq','support vector','logistic reg','naive bayes','perceptron','ridge reg','random forest']\n",
    "for fit in fits:\n",
    "    FP_rate.append(fit.performance_measures['FP'] / fit.performance_measures['Neg'])\n",
    "    TP_rate.append(fit.performance_measures['TP'] / fit.performance_measures['Pos'])\n",
    "    \n",
    "df = pd.DataFrame({\"True Positive Rate\":TP_rate, \"False Positive Rate\": FP_rate, \"Rows\": rows})\n",
    "train_table = pd.pivot_table(df, values=[\"True Positive Rate\",\"False Positive Rate\"], index=[\"Rows\"]).sort_values(by=['True Positive Rate'],ascending=False)\n",
    "\n",
    "column_order=[\"True Positive Rate\",\"False Positive Rate\"]\n",
    "train_table = train_table.reindex(column_order, axis=1)\n",
    "\n",
    "print(train_table)\n",
    "                   True Positive Rate  False Positive Rate\n",
    "Rows                                                      \n",
    "logistic reg                   1.0000               0.0000\n",
    "naive bayes                    1.0000               0.0000\n",
    "perceptron                     1.0000               0.0000\n",
    "ridge reg                      1.0000               0.0000\n",
    "support vector                 1.0000               0.0000\n",
    "random forest                  0.8334               0.3444\n",
    "ordinary least sq              0.5153               0.4697\n",
    "looking at reviews based on their classification\n",
    "Let's say we decide that Ordinary Least Squares (OLS) Regression is the best model for generalization. Let's take a look at some of the reviews and try to make a (subjective) determination of whether it's generalizing well.\n",
    "\n",
    "rdg_predictions = rdg.predict(X_train)\n",
    "let's look at some false positives:\n",
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(rdg_predictions)):\n",
    "    if (rdg_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['sentiment'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['review'])\n",
    "                print('* * * * * * * * * ')\n",
    "Examples of false positives:\n",
    "WARNING: Don't look at test set performance too much!\n",
    "The following cells show performance on your test set. Do not look at this too often!\n",
    "\n",
    "Look at performance on the test set\n",
    "MODEL: ordinary least squares\n",
    "ols_performance_test = BinaryClassificationPerformance(ols.predict(X_test), y_test, 'ols_test')\n",
    "ols_performance_test.compute_measures()\n",
    "print(ols_performance_test.performance_measures)\n",
    "{'Pos': 2500, 'Neg': 2500, 'TP': 1255, 'TN': 1362, 'FP': 1138, 'FN': 1245, 'Accuracy': 0.5234, 'Precision': 0.5244463017133305, 'Recall': 0.502, 'desc': 'ols_test'}\n",
    "MODEL: SVM, linear\n",
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)\n",
    "{'Pos': 2500, 'Neg': 2500, 'TP': 2120, 'TN': 2102, 'FP': 398, 'FN': 380, 'Accuracy': 0.8444, 'Precision': 0.8419380460683081, 'Recall': 0.848, 'desc': 'svm_test'}\n",
    "MODEL: logistic regression\n",
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(lgs_performance_test.performance_measures)\n",
    "{'Pos': 2500, 'Neg': 2500, 'TP': 2099, 'TN': 2148, 'FP': 352, 'FN': 401, 'Accuracy': 0.8494, 'Precision': 0.8563851489188087, 'Recall': 0.8396, 'desc': 'lgs_test'}\n",
    "MODEL: Naive Bayes\n",
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X_test), y_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(nbs_performance_test.performance_measures)\n",
    "{'Pos': 2500, 'Neg': 2500, 'TP': 2018, 'TN': 2142, 'FP': 358, 'FN': 482, 'Accuracy': 0.832, 'Precision': 0.8493265993265994, 'Recall': 0.8072, 'desc': 'nbs_test'}\n",
    "MODEL: Perceptron\n",
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)\n",
    "{'Pos': 2500, 'Neg': 2500, 'TP': 2114, 'TN': 2117, 'FP': 383, 'FN': 386, 'Accuracy': 0.8462, 'Precision': 0.8466159391269523, 'Recall': 0.8456, 'desc': 'prc_test'}\n",
    "MODEL: Ridge Regression Classifier\n",
    "rdg_performance_test = BinaryClassificationPerformance(rdg.predict(X_test), y_test, 'rdg_test')\n",
    "rdg_performance_test.compute_measures()\n",
    "print(rdg_performance_test.performance_measures)\n",
    "{'Pos': 2500, 'Neg': 2500, 'TP': 2308, 'TN': 2207, 'FP': 293, 'FN': 192, 'Accuracy': 0.903, 'Precision': 0.8873510188389081, 'Recall': 0.9232, 'desc': 'rdg_test'}\n",
    "MODEL: Random Forest Classifier\n",
    "rdf_performance_test = BinaryClassificationPerformance(rdf.predict(X_test), y_test, 'rdf_test')\n",
    "rdf_performance_test.compute_measures()\n",
    "print(rdf_performance_test.performance_measures)\n",
    "print(rdf_performance_test)\n",
    "{'Pos': 2500, 'Neg': 2500, 'TP': 2042, 'TN': 1606, 'FP': 894, 'FN': 458, 'Accuracy': 0.7296, 'Precision': 0.6955040871934605, 'Recall': 0.8168, 'desc': 'rdf_test'}\n",
    "<my_measures.BinaryClassificationPerformance object at 0x7fdbb25aeb20>\n",
    "ROC plot to compare performance of various models and fits\n",
    "fits = [svm_performance_test, lgs_performance_test, nbs_performance_test, prc_performance_test, rdg_performance_test]\n",
    "fig = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0.4, 1])\n",
    "plt.yticks(np.arange(0.4, 1, 0.05))\n",
    "plt.title('ROC plot: test set')\n",
    "plt.ylabel('True positive rate/Recall')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.show()\n",
    "\n",
    "Create Pivot Table\n",
    "#https://pavopax.github.io/2017/11/precision-recall/\n",
    "#https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba#:~:text=Recall%20and%20True%20Positive%20Rate,denominator%20contains%20the%20true%20negatives.\n",
    "fits = [ols_performance_test, svm_performance_test, lgs_performance_test, nbs_performance_test, prc_performance_test, rdg_performance_test, rdf_performance_test]\n",
    "TP_rate =[]\n",
    "FP_rate =[]\n",
    "rows = ['ordinary least sq','support vector','logistic reg','naive bayes','perceptron','ridge reg','random forest']\n",
    "for fit in fits:\n",
    "    FP_rate.append(fit.performance_measures['FP'] / fit.performance_measures['Neg'])\n",
    "    TP_rate.append(fit.performance_measures['TP'] / fit.performance_measures['Pos'])\n",
    "    \n",
    "df = pd.DataFrame({\"True Positive Rate\":TP_rate, \"False Positive Rate\": FP_rate, \"Rows\": rows})\n",
    "test_table = pd.pivot_table(df, values=[\"True Positive Rate\",\"False Positive Rate\"], index=[\"Rows\"]).sort_values(by=['True Positive Rate'],ascending=False)\n",
    "\n",
    "column_order=[\"True Positive Rate\",\"False Positive Rate\"]\n",
    "test_table = test_table.reindex(column_order, axis=1)\n",
    "\n",
    "print(test_table)\n",
    "                   True Positive Rate  False Positive Rate\n",
    "Rows                                                      \n",
    "ridge reg                      0.9244               0.1308\n",
    "logistic reg                   0.8472               0.1524\n",
    "perceptron                     0.8456               0.1624\n",
    "support vector                 0.8352               0.1512\n",
    "random forest                  0.8024               0.3056\n",
    "naive bayes                    0.7960               0.1608\n",
    "ordinary least sq              0.3436               0.3220\n",
    "SUBMISSION\n",
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = process_raw_data(fn='../data/moviereviews_test.tsv', my_random_seed=73, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 25,000): \")\n",
    "         id                                             review\n",
    "0  12311_10  Naturally in a film who's main themes are of m...\n",
    "1    8348_2  This movie is a disaster within a disaster fil...\n",
    "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
    "3    7186_2  Afraid of the Dark left me with the impression...\n",
    "4   12128_7  A very accurate depiction of small time mob li...\n",
    "5    2913_8  ...as valuable as King Tut's tomb! (OK, maybe ...\n",
    "6    4396_1  This has to be one of the biggest misfires eve...\n",
    "7     395_2  This is one of those movies I watched, and won...\n",
    "8   10616_1  The worst movie i've seen in years (and i've s...\n",
    "9    9074_9  Five medical students (Kevin Bacon, David Labr...\n",
    "movie_data is: <class 'pandas.core.frame.DataFrame'>\n",
    "movie_data has 25000 rows and 2 columns \n",
    "\n",
    "the data types for each of the columns in movie_data:\n",
    "id        object\n",
    "review    object\n",
    "dtype: object \n",
    "\n",
    "the first 10 rows in movie_data:\n",
    "         id                                             review\n",
    "0  12311_10  Naturally in a film who's main themes are of m...\n",
    "1    8348_2  This movie is a disaster within a disaster fil...\n",
    "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
    "3    7186_2  Afraid of the Dark left me with the impression...\n",
    "4   12128_7  A very accurate depiction of small time mob li...\n",
    "Shape of HashingVectorizer X:\n",
    "(25000, 1513832)\n",
    "Look at a few rows of the new quantitative features: \n",
    "   word_count  punc_count\n",
    "0         131           5\n",
    "1         169          15\n",
    "2         176          18\n",
    "3         112           5\n",
    "4         133           8\n",
    "5         331          20\n",
    "6         121          18\n",
    "7         230          22\n",
    "8          59           3\n",
    "9         224          14\n",
    "Size of combined bag of words and new quantitative variables matrix:\n",
    "(25000, 1513834)\n",
    "(25000, 1513834)\n",
    "Shape of X_test for submission:\n",
    "(25000, 1513834)\n",
    "SUCCESS!\n",
    "Number of rows in the submission test set (should be 25,000): \n",
    "Choose a *single* model for your submission. In this code, I am choosing the Ordinary Least Squares model fit, which is in the ols object. But you should choose the model that is performing the best for you!\n",
    "\n",
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = rdg.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())\n",
    "0.49696\n",
    "raw_data.head()\n",
    "id\treview\tword_count\tpunc_count\n",
    "0\t12311_10\tNaturally in a film who's main themes are of m...\t131\t5\n",
    "1\t8348_2\tThis movie is a disaster within a disaster fil...\t169\t15\n",
    "2\t5828_4\tAll in all, this is a movie for kids. We saw i...\t176\t18\n",
    "3\t7186_2\tAfraid of the Dark left me with the impression...\t112\t5\n",
    "4\t12128_7\tA very accurate depiction of small time mob li...\t133\t8\n",
    "my_submission.head()\n",
    "id\tprediction\n",
    "0\t12311_10\t1\n",
    "1\t8348_2\t0\n",
    "2\t5828_4\t1\n",
    "3\t7186_2\t0\n",
    "4\t12128_7\t1\n",
    "my_submission.shape\n",
    "(25000, 2)\n",
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('../data/moviereviews_submissions02.csv', index=False)\n",
    "Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
