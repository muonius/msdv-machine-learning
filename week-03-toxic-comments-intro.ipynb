{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and specifications\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#display output inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './data/toxiccomments_train.csv'\n",
    "toxic_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Overview ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data value is: <class 'numpy.ndarray'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "data types for each columns are the following:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "word_count        int64\n",
      "dtype: object \n",
      "\n",
      "the first 6 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  word_count  \n",
      "0             0        0       0       0              0          42  \n",
      "1             0        0       0       0              0          18  \n",
      "2             0        0       0       0              0          42  \n",
      "3             0        0       0       0              0         112  \n",
      "4             0        0       0       0              0          13  \n",
      "5             0        0       0       0              0          12  \n"
     ]
    }
   ],
   "source": [
    "print(\"toxic_data is:\", type(toxic_data))\n",
    "print(\"toxic_data value is:\", type(toxic_data.values))\n",
    "print(\"toxic_data has\", toxic_data.shape[0],\"rows and\", toxic_data.shape[1], \"columns\",\"\\n\")\n",
    "print(\"data types for each columns are the following:\")\n",
    "print(toxic_data.dtypes,\"\\n\")\n",
    "print(\"the first 6 rows in toxic_data:\")\n",
    "print(toxic_data.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a feature that is word count for each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        comment_text  word_count\n",
      "0  Explanation\\nWhy the edits made under my usern...          42\n",
      "1  D'aww! He matches this background colour I'm s...          18\n",
      "2  Hey man, I'm really not trying to edit war. It...          42\n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...         112\n",
      "4  You, sir, are my hero. Any chance you remember...          13\n"
     ]
    }
   ],
   "source": [
    "toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "print(toxic_data[[\"comment_text\",\"word_count\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Plot relationship between word count and toxic labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7faf298d1880>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(toxic_data[\"word_count\"],toxic_data[\"toxic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 159571\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows of data:\",toxic_data[\"toxic\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg toxic label value 9.58%\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg toxic label value\",\"{0:.2f}%\".format(toxic_data[\"toxic\"].mean()*100,\"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and columns respectively for non_toxic data: (144277, 9)\n"
     ]
    }
   ],
   "source": [
    "non_toxic = toxic_data.loc[toxic_data[\"toxic\"]==0]\n",
    "print(\"Rows and columns respectively for non_toxic data:\", non_toxic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there, \n",
      "\n",
      " Is there any specific reason why you targeted and gutted all the articles I had helpfully contributed to?  There didn't seem to be  a legitimate reason to remove any of the accurate and useful information I added to individual articles off the Ring of Honor employee page. While I am sure you had your reasons I respectfully request you refresh your memory by going to Wikipedia's articles pertaining to Good Faith Edits and remaining civil. Thank you very much and have a great day! \n",
      "\n",
      "*****************\n",
      "That makes three experienced admins that you take issue with upon the proper application of WP policy. Since you are not Galileo and we are not the Spanish Inquisition then you may wish to deliberate upon the concept that you might be wrong (or the concept of admitting the possibility that there may be times when you could be wrong, if the former is too much of a leap for you). \n",
      "\n",
      "*****************\n",
      "Barrett on Corporal Clegg \n",
      "\n",
      "Some source I've read in the late 15 years and over (since I'm a Floyd Fan), refer to the presence of Barrett playing guitar with Gilmour also in CORPORAL CLEGG. Is it true? \n",
      "\n",
      "*****************\n",
      "Well you're the only one that is contradicting against me, a lot of other people have posted information which they believed were correct and it's always you that reverts the information they edited. \n",
      "\n",
      "Therefore I don't trust you, I believe that you're deliberately harassing other users. \n",
      "\n",
      "*****************\n",
      "\"\n",
      "\n",
      "Murtha calls U.S. Marines \"\"cold-blooded killers\"\"\n",
      "\n",
      "Someone needs to type up a section on this.  I think it's a pretty big deal when an elected representive calls our soldiers war criminals before their American right to a fair trial even begins.  Regardless of your pro-war/anti-war position, Murtha is a total disgrace.\" \n",
      "\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "sampling = non_toxic[\"comment_text\"].sample(n=5, random_state=10)\n",
    "#random_state is randomSeed in python\n",
    "for sample in sampling:\n",
    "    print(sample,'\\n')\n",
    "    print('*****************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
